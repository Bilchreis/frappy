{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "\tinvGamma = 1.0 / gamma\n",
    "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
    "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\t# apply gamma correction using the lookup table\n",
    "\treturn cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread('saved_qr_img_2.png')\n",
    "\n",
    "img = adjust_gamma(img, gamma=0.3)\n",
    "\n",
    "\n",
    "# ksize \n",
    "ksize = (20, 20) \n",
    "  \n",
    "# Using cv2.blur() method  \n",
    "img = cv2.blur(img, ksize, cv2.BORDER_DEFAULT)\n",
    "\n",
    "\n",
    "down_width = 900\n",
    "down_height = 900\n",
    "down_points = (down_width, down_height)\n",
    "img = cv2.resize(img, down_points, interpolation= cv2.INTER_LINEAR)\n",
    "\n",
    "#img = cv2.bitwise_not(img)\n",
    "\n",
    "#ret, thresh = cv2.threshold(img, 90,255,cv2.THRESH_BINARY )\n",
    "#img = cv2.bitwise_not(thresh, thresh)\n",
    "\n",
    "print(np.amax(img))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite(\"processed.png\", img)\n",
    "\n",
    "#qcd = cv2.QRCodeDetector()\n",
    "\n",
    "#qcd.detectAndDecodeMulti(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qreader import QReader\n",
    "\n",
    "for i in range(1, 7):\n",
    "\n",
    "    img = cv2.imread(f'saved_qr_img_{i}.png')\n",
    "\n",
    "\n",
    "    #img = cv2.bitwise_not(img)\n",
    "    qreader = QReader()\n",
    "\n",
    "\n",
    "    sample_id =qreader.detect_and_decode(image=img)\n",
    "\n",
    "    print(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statemachine import StateMachine, State, Event\n",
    "\n",
    "\n",
    "class TrafficLightMachine(StateMachine):\n",
    "    \"A traffic light machine\"\n",
    "    green = State(name = 'green', initial=True,value='green')\n",
    "    yellow = State('yellow','yellow')\n",
    "    red = State('red','red')\n",
    "\n",
    "    cycle = (\n",
    "        green.to(yellow)\n",
    "        | yellow.to(red)\n",
    "        | red.to(green)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def mount_ok_callback():\n",
    "    print(\"mount ok\")\n",
    "    \n",
    "def unmount_ok_callback():\n",
    "    print(\"unmount ok\")\n",
    "    \n",
    "def mount_error_callback():\n",
    "    print(\"mount error\")\n",
    "    \n",
    "def unmount_error_callback():\n",
    "    print(\"unmount error\")\n",
    "    \n",
    "callbacks =   [\n",
    "            ('ok','green',mount_ok_callback),\n",
    "            ('ok','yellow',unmount_ok_callback),\n",
    "            ('error','mount',mount_error_callback),\n",
    "            ('error','unmount',unmount_error_callback)\n",
    "        ]\n",
    "\n",
    "\n",
    "def run_OK_callbacks(sm:TrafficLightMachine):   \n",
    "    for callback_tuple in callbacks:\n",
    "        match callback_tuple:\n",
    "            case ('ok',sm.current_state.value, callback):\n",
    "                callback()\n",
    "                return\n",
    "            \n",
    "    print(\"no callback found\")\n",
    "                \n",
    "\n",
    "\n",
    "lights  = TrafficLightMachine()\n",
    "print(lights.current_state.id)\n",
    "run_OK_callbacks(lights)\n",
    "\n",
    "lights.cycle()\n",
    "print(lights.current_state.id)\n",
    "run_OK_callbacks(lights)\n",
    "\n",
    "lights.cycle()\n",
    "print(lights.current_state.id)\n",
    "run_OK_callbacks(lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding Image: 1\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n",
      "callback input: HZB-V1.0-1test01\n",
      "Decoding Image: 2\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n",
      "callback input: HZB-V0.1-01234\n",
      "Decoding Image: 3\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n",
      "callback input: HZB-V1.0-1test03\n",
      "Decoding Image: 4\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n",
      "callback input: HZB-V1.0-1test02\n",
      "Decoding Image: 5\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n",
      "Decoding Image: 6\n",
      "creating task for normal image:\n",
      "creating task for inverted image:\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from qreader import QReader\n",
    "import cv2\n",
    "\n",
    "qreader = QReader()\n",
    "qreader_inv = QReader()\n",
    "\n",
    "def decode_img(img):\n",
    "    \n",
    "   \n",
    "    qreader = QReader()\n",
    "    # detect and decode\n",
    "    sample_ids = qreader.detect_and_decode(image=img)\n",
    "    #retval, decoded_info, points, straight_qrcode = self.qcd.detectAndDecodeMulti(img)\n",
    "    # if there is a QR code\n",
    "    # print the data\n",
    "\n",
    "    \n",
    "    if sample_ids != () and sample_ids != (None,):\n",
    "        \n",
    "        #print(f\"callback input: {sample_ids[0]}\")\n",
    "        return(sample_ids[0])\n",
    "    \n",
    "    #raise Exception('could not detect qrcode')\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def decode_qr(img):\n",
    "    \n",
    "    inv_img = cv2.bitwise_not(img)      \n",
    "\n",
    "    print('creating task for normal image:')\n",
    "    task_normal = asyncio.create_task(\n",
    "        asyncio.to_thread(decode_img,img)\n",
    "    )\n",
    "    \n",
    "    print('creating task for inverted image:')\n",
    "    task_inverted = asyncio.create_task(\n",
    "        asyncio.to_thread(decode_img,inv_img)\n",
    "    )\n",
    "    \n",
    "    await asyncio.wait([task_normal,task_inverted], return_when=asyncio.FIRST_COMPLETED)\n",
    "    \n",
    "    if task_normal.done() and task_normal.result():\n",
    "        print(f\"callback input: {task_normal.result()}\")\n",
    "\n",
    "    if task_inverted.done() and task_inverted.result():\n",
    "        print(f\"callback input: {task_inverted.result()}\")\n",
    "    \n",
    "    task_inverted.cancel()\n",
    "    task_normal.cancel()\n",
    "    \n",
    "\n",
    "for i in range(1, 7):\n",
    "    print(f\"Decoding Image: {i}\" )\n",
    "    img = cv2.imread(f'saved_qr_img_{i}.png')\n",
    "\n",
    "    await decode_qr(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "._venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
